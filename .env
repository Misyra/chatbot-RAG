# Ollama服务器配置
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=deepseek-r1:7b

# 嵌入模型设置
EMBEDDINGS_MODEL=BGE-M3:latest

# 缓存设置
MAX_CACHE_SIZE=1000
CACHE_TTL=3600

# 调试设置
DEBUG_MODE=false
LOG_LEVEL=DEBUG
VECTOR_STORE_DEBUG=false
LOG_FILE=./logs/vector_store.log

# 向量存储调试设置
VECTOR_STORE_DEBUG=False

